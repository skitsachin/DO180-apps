1. Overview
You have two Kubernetes clusters:

Blue (Active): Currently serving GitLab Runner workloads.

Green (Standby): Synchronized and kept ready for failover.

If the Blue cluster becomes unavailable (e.g., infra failure, upgrades gone wrong), you failover to the Green cluster.

2. Assumptions
You are using Helm to deploy GitLab Runner.

GitLab Runner is configured via a GitOps pipeline or Helm chart values stored in source control.

GitLab Runners register via token from GitLab (you have this stored securely).

GitLab Runner is stateless or uses persistent storage with cross-cluster backups (like cloud-based volumes or S3-backed cache).

DNS, GitLab instance, and secrets are accessible from both clusters.

3. Pre-Recovery (Preventive Measures)
3.1 Continuous Sync (Green Cluster)
Use GitOps (e.g., ArgoCD, Flux) or scheduled Helm upgrades to keep Green in sync with Blue.

Periodically validate runner registration in both clusters.

Use Kubernetes Sealed Secrets, External Secrets, or HashiCorp Vault to sync secrets across clusters.

3.2 Cross-Cluster Resources
Ensure the following are shared or replicated:

Runner registration tokens

Artifact storage (S3, GCS, etc.)

Docker registry credentials

Persistent volume snapshots or backups

Helm release values (values.yaml) stored in Git

4. Failover Plan (Active Cluster Failure)
ðŸ’¥ Scenario: Blue cluster fails (runner pods stop working, cluster is degraded)

Step 1: Confirm Cluster Failure
Confirm unavailability of GitLab Runner in Blue cluster via:

bash
Copy
Edit
kubectl get pods -n gitlab-runner --context=blue
Check health via observability tools or GitLab job failure logs.

Step 2: Promote Green Cluster
Switch context to the Green cluster:

bash
Copy
Edit
kubectl config use-context green
If using Helm:

Ensure GitLab Runner is installed with same config:

bash
Copy
Edit
helm upgrade --install gitlab-runner gitlab/gitlab-runner \
  -n gitlab-runner \
  -f gitlab-runner-values.yaml
If using GitOps (ArgoCD, Flux), trigger a sync or rollback as needed.

Step 3: Update DNS/Networking
If Runners are exposed via an ingress or public IP:

Update DNS (e.g., runner.company.com) to point to the Green cluster.

If using GitLab SaaS, ensure it sees new runner heartbeat.

Step 4: Verify Runners in Green
Validate that the runner pods are running:

bash
Copy
Edit
kubectl get pods -n gitlab-runner --context=green
Confirm runners are registered in GitLab (Admin Area â†’ CI/CD â†’ Runners).

Run a test pipeline to validate job pickup.

5. Recovery of Blue Cluster (Optional)
After the incident is resolved, you may want to sync Blue back to Green and revert roles.

Step 1: Restore Cluster Health
Reboot or fix infrastructure.

Reconnect storage/networking as needed.

Step 2: Resync Blue from Git
Apply Helm/GitOps again on Blue cluster:

bash
Copy
Edit
helm upgrade --install gitlab-runner gitlab/gitlab-runner \
  -n gitlab-runner \
  -f gitlab-runner-values.yaml
Step 3: Resync Secrets
Reapply secrets using Git or your secret manager.

Step 4: Failback (Optional)
Once Blue is healthy and validated, switch DNS or runner registration back.

6. Validations After Failover
âœ… GitLab Runner is listed and active in GitLab.

âœ… Pipelines are executing jobs on the new cluster.

âœ… Artifact storage and cache are still functional.

âœ… Logs from jobs are available and correct.

âœ… No secrets are missing (Docker credentials, GitLab token).

7. Documentation and Audit
Log the failover in your incident tracking system.

Review recovery duration, any manual steps needed.

Update DR runbook if gaps were identified.

âœ… TL;DR â€” DR in Blue-Green Setup
Action	Description
Failover	Promote Green to active (runner ready, DNS switched).
Recover	Repair and resync Blue with Green.
Rollback	Optional failback after Blue is healthy.
Validation	Check job execution, runner status, secrets, and logs.
